{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tfsl2F-83i_1"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducbiity (trying to take out of random\n",
        "\n",
        "In short how a neural network earns:\n",
        "\n",
        "start with random numbers -> tensor operations -> update random numbers to try and make them of the data ->again ->again ->again ....\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a random seed.\n",
        "Essentially what the random seed does is \"flavour\" the randomness.\n"
      ],
      "metadata": {
        "id": "v_RYjJGZ4EwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyRq3tFY4te7",
        "outputId": "8381be88-2d86-4fb6-f24a-99a081c3d58d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3663, 0.2826, 0.7181],\n",
              "        [0.0742, 0.9184, 0.9617],\n",
              "        [0.6196, 0.7021, 0.4293]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#create two random tensors\n",
        "random_tensor_A=torch.rand(3,4)\n",
        "random_tensor_B=torch.rand(3,4)\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A==random_tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-zgzKtW4xC5",
        "outputId": "dc9e4e12-987c-4b10-8e0d-6255a8f77138"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0382, 0.5364, 0.6071, 0.0906],\n",
            "        [0.7420, 0.7065, 0.5755, 0.6420],\n",
            "        [0.6048, 0.5161, 0.7920, 0.4975]])\n",
            "tensor([[0.8124, 0.8481, 0.5365, 0.3184],\n",
            "        [0.7619, 0.0934, 0.8658, 0.6534],\n",
            "        [0.3781, 0.9857, 0.4804, 0.5287]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make some random but reproduciable tensors\n",
        "import torch\n",
        "# set the random seed\n",
        "Random_seed=42\n",
        "torch.manual_seed(Random_seed)\n",
        "random_tensor_C=torch.rand(3,4)\n",
        "\n",
        "\n",
        "random_tensor_D=torch.rand(3,4)\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C==random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDjNdCef54AC",
        "outputId": "fc775450-8e87-4632-9d57-b9d584019de6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make some random but reproduciable tensors\n",
        "import torch\n",
        "# set the random seed\n",
        "Random_seed=42\n",
        "torch.manual_seed(Random_seed)\n",
        "random_tensor_C=torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(Random_seed)\n",
        "random_tensor_D=torch.rand(3,4)\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C==random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xUipGK267Av",
        "outputId": "4a003149-3479-4b86-8af9-163bce5b6f99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors and pytorch objects on the GPUs( and making faster computations)\n",
        "\n",
        "GPUs=faster computation on numbers,thanks to CUDA+NVIDIA hardware+PyTorch working behind the sceries to make everything hunky dory(good)"
      ],
      "metadata": {
        "id": "j3FX9IBy8g13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting a GPU\n",
        "1. Easiest- use google colab for a free GPU(options to upgrade as well)\n",
        "2. Use your own GPU-takes a little bit of setup and requires the investment of purchasing a GPU ,there's lots of options...,\n",
        "3. Use cloud computing -GPU,AWS ,Azure,these services aow you to rent computers on the cloud and access them.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wlhnTXBg89Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "jFvrX3-v8X83"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKdL0GwZ_H_J",
        "outputId": "96800463-25c0-4844-a0bd-8c7f6bf019ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 20 05:30:48 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### check for GPU access with PyTorch"
      ],
      "metadata": {
        "id": "l5RX4PS4_rsA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU access with PyTorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8jY75COAANG",
        "outputId": "71dd3c95-60bf-4c22-95e3-c0958c6eac80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup device agostic code\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NB4n0GYJKK13",
        "outputId": "d8afe4f1-0b1c-41f4-bcda-71743c1462f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLoMEXj7KdsQ",
        "outputId": "5f75c318-abde-4f73-c386-8e6759dade6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### putting tensors (and models) on the GPU\n",
        "the reason we went our tensors/models on the GPU is because using a GPU resuls in faster computations."
      ],
      "metadata": {
        "id": "rJ4kj9A0Kw3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor (default on the CPU)\n",
        "tensor=torch.tensor([1,2,3])\n",
        "# Tensor not on GPU\n",
        "print(tensor,tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9AS1D52Ldu9",
        "outputId": "36fa7ffb-7747-4c09-ca88-e4d113330e7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move tensor to GPU(if available)\n",
        "tensor_on_gpu=tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhS81QOELugq",
        "outputId": "42fbe57e-fc91-4244-da11-c7ce6542e36e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## moving tensors back to the cpu"
      ],
      "metadata": {
        "id": "L0adzPQ-MMgl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if tensor is on GPU ,can't transform it to Numpy\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "pOJ1FHwoMXaK",
        "outputId": "85e50410-6542-40b9-a58d-8f76fc22328e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-412582c18043>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if tensor is on GPU ,can't transform it to Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to fix the GPU tensor with Numpy issue,we can first set it to the cpu\n",
        "tensor_back_on_cpu=tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhQ-tqVAMjCi",
        "outputId": "4a2e25f4-d80d-4c78-a5ee-c5eaaf0f51cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-t5xX8TM4aX",
        "outputId": "11e81969-3b62-4baf-b02b-384bded0d921"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zVskISrNA2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}